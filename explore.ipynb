{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.12.1)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 2230 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 254 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 399 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/Users/alyssonamaral/Documents/gcn/images'\n",
    "\n",
    "dogs_dir = os.path.join(base_dir, 'Dog')\n",
    "cats_dir = os.path.join(base_dir, 'Cat')\n",
    "\n",
    "def load_and_resize_images(folder, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img_resized = cv2.resize(img, target_size)\n",
    "            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)  # Converter BGR para RGB\n",
    "            img_tensor = torch.from_numpy(img_rgb).permute(2, 0, 1).float()  # Converter para tensor e permutar dimensões\n",
    "            images.append(img_tensor)\n",
    "    return images\n",
    "\n",
    "dog_images = load_and_resize_images(dogs_dir)\n",
    "cat_images = load_and_resize_images(cats_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_graph(image):\n",
    "    channels, height, width = image.shape\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            rgb_values = image[:, i, j].float()  # Extrai o valor RGB de cada pixel no formato (C, H, W)\n",
    "            graph.add_node((i, j), rgb=rgb_values)\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            neighbors = [\n",
    "                (i-1, j), (i+1, j), (i, j-1), (i, j+1),\n",
    "                (i-1, j-1), (i-1, j+1), (i+1, j-1), (i+1, j+1)\n",
    "            ]\n",
    "            for ni, nj in neighbors:\n",
    "                if 0 <= ni < height and 0 <= nj < width:\n",
    "                    diff = torch.norm(image[:, i, j].float() - image[:, ni, nj].float())\n",
    "                    graph.add_edge((i, j), (ni, nj), weight=diff)\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.12.1)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "class MessagePassingLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(MessagePassingLayer, self).__init__()\n",
    "        # Aqui, ajustamos para 2 * input_dim para refletir o vetor concatenado (nó + vizinhos)\n",
    "        self.message_mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, graph):\n",
    "        new_node_features = {}\n",
    "        \n",
    "        for node in graph.nodes:\n",
    "            node_feature = graph.nodes[node][\"rgb\"]\n",
    "            neighbor_features = [graph.nodes[neighbor][\"rgb\"] for neighbor in graph.neighbors(node)]\n",
    "            \n",
    "            if neighbor_features:\n",
    "                aggregated_message = torch.mean(torch.stack(neighbor_features), dim=0)\n",
    "            else:\n",
    "                aggregated_message = torch.zeros_like(node_feature)\n",
    "            \n",
    "            # Concatenamos a característica do nó com a mensagem agregada\n",
    "            combined = torch.cat([node_feature, aggregated_message])\n",
    "            new_node_feature = self.message_mlp(combined)\n",
    "            new_node_features[node] = new_node_feature\n",
    "\n",
    "        for node, new_feature in new_node_features.items():\n",
    "            graph.nodes[node][\"rgb\"] = new_feature\n",
    "\n",
    "        return graph\n",
    "\n",
    "\n",
    "# Função para agregar os valores dos nós em um vetor\n",
    "def aggregate_graph_features(graph):\n",
    "    node_features = torch.stack([graph.nodes[node][\"rgb\"] for node in graph.nodes])\n",
    "    aggregated_vector = torch.mean(node_features, dim=0)  # Agrega usando a média\n",
    "    return aggregated_vector\n",
    "\n",
    "# Classe do modelo MLP final para classificação\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "# Parâmetros para o modelo\n",
    "T = 15\n",
    "input_dim = 3\n",
    "hidden_dim = 64\n",
    "output_dim = 2\n",
    "\n",
    "message_passing_layer = MessagePassingLayer(input_dim, hidden_dim)\n",
    "classification_model = SimpleMLP(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(list(message_passing_layer.parameters()) + list(classification_model.parameters()), lr=0.001)\n",
    "\n",
    "# Carrega e transforma as imagens em grafos\n",
    "dog_graphs = [image_to_graph(img) for img in dog_images]\n",
    "cat_graphs = [image_to_graph(img) for img in cat_images]\n",
    "\n",
    "# Divide os grafos e rótulos em treino e teste\n",
    "graphs = dog_graphs + cat_graphs\n",
    "labels = [0] * len(dog_graphs) + [1] * len(cat_graphs)\n",
    "train_graphs, test_graphs, train_labels, test_labels = train_test_split(graphs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Função para processar os grafos e passar por rounds de message passing\n",
    "def process_graphs(graphs, T):\n",
    "    processed_vectors = []\n",
    "    for graph in graphs:\n",
    "        for _ in range(T):\n",
    "            graph = message_passing_layer(graph)\n",
    "        aggregated_vector = aggregate_graph_features(graph)\n",
    "        processed_vectors.append(aggregated_vector)\n",
    "    return torch.tensor(processed_vectors, dtype=torch.float32)\n",
    "\n",
    "# Processa os grafos de treino e teste com a passagem de mensagem\n",
    "X_train_tensor = process_graphs(train_graphs, T)\n",
    "X_test_tensor = process_graphs(test_graphs, T)\n",
    "y_train_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Configura o modelo e o treinamento\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = classification_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Avaliação do modelo\n",
    "with torch.no_grad():\n",
    "    test_outputs = classification_model(X_test_tensor)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "    accuracy = (predicted == y_test_tensor).sum().item() / len(y_test_tensor)\n",
    "    print(f\"Accuracy on test set: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
